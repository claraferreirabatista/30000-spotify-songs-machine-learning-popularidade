{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratamento de Dados\n",
    "<p>Realizaremos um tratamento dos dados visando a preparação para uma futura criação de um modelo preditivo de machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import locale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comando para exibir todas colunas do arquivo\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comando utilizado para carregar o arquivo e armazena-lo como um DataFrame do Pandas\n",
    "#Um DataFrame do Pandas é como se fosse uma planilha do Excel, onde podemos tratar linhas e colunas.\n",
    "df_dados = pd.read_excel(\"dados.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comando utilizado para verificar a quantidade de linhas e colunas do arquivo\n",
    "#Colunas também são chamadas de variáveis.\n",
    "df_dados.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comando utilizado para verificar as linhas iniciais do DataFrame\n",
    "df_dados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comando utilizado para verificar as linhas finais do DataFrame\n",
    "df_dados.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Avaliar o período dos dados coletados\n",
    "inicio = pd.to_datetime(df_dados['DATA_VENDA']).dt.date.min()\n",
    "fim = pd.to_datetime(df_dados['DATA_VENDA']).dt.date.max()\n",
    "print('Período dos dados - De:', inicio, 'Até:',fim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comando utilizado para verificar informações sobre os dados(Tipo de variáveis, Variáveis, Quantidade de registros, etc)\n",
    "\n",
    "#Neste caso a variavel DATA_VENDA deve ser do tipo Date e a variavel VALOR do tipo Float. Precisamos tratar essas variáveis.\n",
    "\n",
    "df_dados.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dessa forma podemos agrupar os valores e identificar se há algum valor discrepante.\n",
    "# Observe que há um valor que foi inserido como \"SEM VALOR\"\n",
    "df_dados.groupby(['VALOR']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui poderíamos resolver de duas formas.\n",
    "\n",
    "# A primeira forma seria excluir todo o registro, mas estariamos perdendo dados.\n",
    "#df_dados.drop(df_dados.loc[df_dados['VALOR']=='SEM VALOR'].index, inplace=True)\n",
    "\n",
    "\n",
    "# A segunda forma seria verificar o valor médio ou da mediana deste modelo e substituir a palavra SEM VALOR para um valor médio.\n",
    "df_dados.loc[df_dados['VALOR'] == 'SEM VALOR']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora substituimos a palavra SEM VALOR pelo valor ZERO\n",
    "df_dados.loc[(df_dados['VALOR'] == 'SEM VALOR'), 'VALOR'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Em seguida convertemos o campo em float\n",
    "df_dados['VALOR'] = df_dados['VALOR'].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos os valores medianos da coluna modelo para substituir o valor ZERO\n",
    "df_dados.loc[df_dados['MODELO'] == 'PASSAT'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui atualizamos o valor conforme a mediana daquele modelo\n",
    "df_dados.loc[(df_dados['VALOR'] == 200000), 'VALOR'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comando utilizado para avaliar se alguma variável possui valor nulo ou chamado de valores missing ou NAN (Not Available)\n",
    "df_dados.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora iremos tratar os valores missing, ou seja, os registros que não possuem valores.\n",
    "# Uma forma bem mais simples de tratarmos o dado é utilizar direto a função FILLNA preenchendo os valores em branco \n",
    "# com a mediana\n",
    "df_dados['KM-LITRO'] = df_dados['KM-LITRO'].fillna((df_dados['KM-LITRO'].median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe agora que não temos mais nenhum valor em branco\n",
    "df_dados.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos avaliar novamente os tipos das variaveis\n",
    "df_dados.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora iremos avaliar os outliers das colunas que são númericas\n",
    "# OUTLIERS são valores discrepantes que estão bem acima ou bem abaixo dos outros valores\n",
    "\n",
    "# Vamos carregar em uma lista as variaveis que são do tipo INT64 E FLOAT64\n",
    "variaveis_numericas = []\n",
    "for i in df_dados.columns[0:48].tolist():\n",
    "        if df_dados.dtypes[i] == 'int64' or df_dados.dtypes[i] == 'float64':            \n",
    "            print(i, ':' , df_dados.dtypes[i]) \n",
    "            variaveis_numericas.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos observar a lista de variáveis e avaliar se nestas variáveis temos outliers através de um boxplot\n",
    "variaveis_numericas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Com este comando iremos exibir todos gráficos de todas colunas de uma vez só para facilitar nossa analise.\n",
    "\n",
    "# Aqui definimos o tamanho da tela para exibição dos gráficos\n",
    "plt.rcParams[\"figure.figsize\"] = [12.00, 14.00]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "# Aqui definimos em quantas linhas e colunas queremos exibir os gráficos\n",
    "f, axes = plt.subplots(3, 2) #3 linhas e 2 colunas\n",
    "\n",
    "linha = 0\n",
    "coluna = 0\n",
    "\n",
    "for i in variaveis_numericas:\n",
    "    sns.boxplot(data = df_dados, y=i, ax=axes[linha][coluna])\n",
    "    coluna += 1\n",
    "    if coluna == 2:\n",
    "        linha += 1\n",
    "        coluna = 0            \n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Boxplots\n",
    "# Boxplot é utilizado para avaliar e comparar o formato, tendência central e variabilidade de distribuições de amostra, \n",
    "# e para procurar por outliers. Por padrão, um boxplot demonstra a mediana, os quartis, \n",
    "# o intervalo interquartil(IQR) e outliers para cada variável. \n",
    "\n",
    "# Outlier são valores que estão bem discrepantes dentro do conjunto de dados, podem ser para mais ou para menos. \n",
    "# Observe nos DOIS ULTIMOS boxplot que há os pontinhos acima das linhas. Esses valores são outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora já sabemos que temos OUTLIERS nas variáveis CAVALOS e VALOR. Vamos olhar quais são esses outliers para avaliar\n",
    "# como iremos trata-los.\n",
    "\n",
    "# Como no boxplot acima mostra que o maior número de cavalos está em torno de 700, então iremos listar os casos acima de 700\n",
    "# Observe que após listarmos só temos um registro com OUTLIER.\n",
    "\n",
    "df_dados.loc[df_dados['CAVALOS'] > 700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nesse exemplo vamos excluir o registro todo.\n",
    "df_dados.drop(df_dados.loc[df_dados['CAVALOS'] == 1800].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora para a variavel VALOR vamos listar os valores maiores que 900.000\n",
    "# Observe que temos dois registros considerados outlier, ou seja, o valor está muito acima do normal.\n",
    "\n",
    "# Neste caso vamos substituir os valores pelo valor médio do modelo LAMBORGUINI.\n",
    "\n",
    "df_dados.loc[df_dados['VALOR'] > 900000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos identificar o valor mediana do modelo LAMBORGUINI\n",
    "\n",
    "df_dados.loc[df_dados['MODELO'] == 'LABORGUINI'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui atualizamos o valor conforme a mediana daquele modelo\n",
    "df_dados.loc[(df_dados['VALOR'] > 900000), 'VALOR'] = 900000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos avaliar novamente os boxplot e verificar se ficou algum OUTLIER\n",
    "# Observe que na coluna cavalos de potencia ainda possuem alguns OUTLIERS porém nesse caso, olhando para o modelos dos carros\n",
    "# podemos observar que realmente é a potencia deles. Nesse caso podemos mante-los.\n",
    "\n",
    "# Aqui definimos o tamanho da tela para exibição dos gráficos\n",
    "plt.rcParams[\"figure.figsize\"] = [12.00, 14.00]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "# Aqui definimos em quantas linhas e colunas queremos exibir os gráficos\n",
    "f, axes = plt.subplots(3, 2) #3 linhas e 2 colunas\n",
    "\n",
    "linha = 0\n",
    "coluna = 0\n",
    "\n",
    "for i in variaveis_numericas:\n",
    "    sns.boxplot(data = df_dados, y=i, ax=axes[linha][coluna])\n",
    "    coluna += 1\n",
    "    if coluna == 2:\n",
    "        linha += 1\n",
    "        coluna = 0            \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Engenharia de Atributos\n",
    "<p> A engenharia de atributos em resumo utilizarmos uma variavel existente e extrairmos mais informações dessa variável, podendo gerar novas variáveis para analise a partir desta variável existente.<br>\n",
    "<p> No exemplo abaixo iremos utilizar a variavel DATA_VENDA e criar variaveis como Ano, Mês e Dia    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora vamos tratar a variavel DATA_VENDA\n",
    "# Aqui iremos fazer um tratamento para transformar o campo para o tipo DATE e também incluirmos novas variáveis a partir da data\n",
    "# Vamos incluir as variaveis separadas, ANO, MES e DIA\n",
    "# Vamos também incluir a variavel DIA_SEMANA e avaliarmos qual dia da semana temos mais vendas.\n",
    "\n",
    "locale.setlocale(locale.LC_ALL, 'pt_BR.utf8')\n",
    "\n",
    "df_dados['DATA_VENDA'] =  pd.to_datetime(df_dados['DATA_VENDA'], format='%d/%m/%Y')\n",
    "df_dados['DATA_VENDA'] = df_dados['DATA_VENDA'].dt.date\n",
    "df_dados['ANO_VENDA'] = pd.DatetimeIndex(df_dados['DATA_VENDA']).year\n",
    "df_dados['MES_VENDA'] = pd.DatetimeIndex(df_dados['DATA_VENDA']).month\n",
    "df_dados['DIA_VENDA'] = pd.DatetimeIndex(df_dados['DATA_VENDA']).day\n",
    "df_dados['DIA_SEMANA_VENDA'] = pd.DatetimeIndex(df_dados['DATA_VENDA']).day_name(locale = 'pt_BR.utf8')\n",
    "\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [8.00, 8.00]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "df_dados.DIA_SEMANA_VENDA.value_counts().plot(kind='bar', title='Vendas Por Dia da Semana',color = ['#1F77B4', '#FF7F0E']);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Também podemos observar as vendas por ano\n",
    "df_dados.ANO_VENDA.value_counts().plot(kind='bar', title='Vendas Por Ano',color = ['#1F77B4', '#FF7F0E']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variaveis Dummys ou One Hot Encoding\n",
    "<p> Quando estamos fazendo o tratamento dos dados para criação de um modelo de Machine Learning ou IA precisamos deixar todos os dados como números.\n",
    "<p> Para este processo utilizamos variaveis Dummys ou também as conhecidas como One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora vou importar uma imagem para explicar o tratamento que iremos fazer das variaveis Dummys/One Hot Encoding\n",
    "from IPython.display import Image\n",
    "Image('exemplo.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antes de gerar as variaveis dummys/one hot encoding vamos excluir as variaveis que não precisaremos mais.\n",
    "# Neste caso vamos excluir a variavel DATA_VENDA, pois já geramos as variaveis separadas de ANO, MES e DIA\n",
    "df_dados.drop('DATA_VENDA', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert os campos categoricos para ONE HOT ENCODING\n",
    "# A imagem abaixo explica de forma simples esse tratamento\n",
    "\n",
    "df_dados = pd.get_dummies(df_dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pronto, agora já temos nosso conjunto de dados tratados.\n",
    "# Vamos salvar esse conjunto de dados com todos tratamentos.\n",
    "df_dados.to_excel('dados_com_tratamento.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
