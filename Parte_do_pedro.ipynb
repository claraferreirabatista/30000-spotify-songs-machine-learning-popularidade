{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "go0dle30f5vP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_parquet('spotify_songs.parquet')"
      ],
      "metadata": {
        "id": "LQWg3tvuf-t8",
        "outputId": "e3c95861-d717-49c7-e360-e27930fc53be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-20eb6855dd1e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'spotify_songs.parquet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0mimpl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m     return impl.read(\n\u001b[0m\u001b[1;32m    504\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, path, columns, use_nullable_dtypes, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0mto_pandas_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"split_blocks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# type: ignore[assignment]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         path_or_handle, handles, kwargs[\"filesystem\"] = _get_path_or_handle(\n\u001b[0m\u001b[1;32m    245\u001b[0m             \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"filesystem\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36m_get_path_or_handle\u001b[0;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;31m# fsspec resources can also point to directories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;31m# this branch is used for example when reading from non-fsspec URLs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         handles = get_handle(\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0mpath_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    863\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 865\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    866\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'spotify_songs.parquet'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume df is your DataFrame containing the Spotify dataset\n",
        "\n",
        "# Handling missing values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Converting 'track_popularity' to categorical labels\n",
        "def classify_popularity(popularity):\n",
        "    if popularity <= 20:\n",
        "        return 0\n",
        "    elif popularity <= 40:\n",
        "        return 1\n",
        "    elif popularity <= 60:\n",
        "        return 2\n",
        "    else:\n",
        "        return 3\n",
        "\n",
        "df['popularity_class'] = df['track_popularity'].apply(classify_popularity)\n"
      ],
      "metadata": {
        "id": "OG8nQNnjgAPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Distribution of popularity classes\n",
        "sns.countplot(x='popularity_class', data=df)\n",
        "plt.title('Distribution of Popularity Classes')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "cHZ5qlJigDFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "df.drop(columns = ['track_name', 'track_artist', 'track_album_id', 'track_album_name', 'playlist_name', 'playlist_id', 'playlist_genre', 'playlist_subgenre'], inplace = True)\n",
        "\n",
        "\n",
        "# Scaling numerical columns\n",
        "numerical_columns = ['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms']\n",
        "scaler = StandardScaler()\n",
        "df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
        "\n",
        "\n",
        "# Convert 'track_album_release_date' to datetime\n",
        "df['track_album_release_date'] = pd.to_datetime(df['track_album_release_date'])\n",
        "\n",
        "# Extract year, month, day information\n",
        "df['release_year'] = df['track_album_release_date'].dt.year\n",
        "\n",
        "filtered_df = df[df['release_year'] >= 2019]\n",
        "# Drop the original 'track_album_release_date' column\n",
        "filtered_df.drop(columns=['track_album_release_date', 'release_year','track_popularity'], inplace=True)"
      ],
      "metadata": {
        "id": "Fq41SCsegHVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate correlation matrix\n",
        "corr_matrix = filtered_df.corr()\n",
        "\n",
        "# Plot correlation heatmap\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B4MvoRotgJXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df.info()"
      ],
      "metadata": {
        "id": "DgyG4bh5khwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution of popularity classes\n",
        "sns.countplot(x='popularity_class', data=filtered_df)\n",
        "plt.title('Distribution of Popularity Classes')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "qq5uW7t-ltXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from collections import Counter\n",
        "# separando quem é feature e quem é target\n",
        "X = filtered_df.drop(columns=[ 'popularity_class'])\n",
        "y = filtered_df['popularity_class']\n",
        "\n",
        "# Splitting dos dados\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Original dataset shape\", Counter(y_train))\n",
        "\n",
        "sm = RandomUnderSampler(random_state=42)\n",
        "X_res, y_res = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"Dataset shape undersampling\", Counter(y_res))"
      ],
      "metadata": {
        "id": "VvJCY4pusyy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df.to_csv('filtered_df.csv', index=False)"
      ],
      "metadata": {
        "id": "P01EXHBFzSRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM - TESTAR MAIS HIPERPARAMETROS\n",
        "svm_model = SVC(kernel='linear')  # You can try different kernels and hyperparameters\n",
        "\n",
        "# Treinando modelo\n",
        "svm_model.fit(X_res, y_res)\n",
        "\n",
        "# Predict\n",
        "predictions = svm_model.predict(X_test)\n",
        "\n",
        "# Avaliando\n",
        "print(classification_report(y_test, predictions))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, predictions))"
      ],
      "metadata": {
        "id": "J9oextLwtWib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(y_test, predictions)\n",
        "plot_confusion_matrix(conf_mat = cm, show_normed = True, class_names = [0,1,2,3])"
      ],
      "metadata": {
        "id": "0QabrDUmz21K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM - TESTAR MAIS HIPERPARAMETROS\n",
        "svm_model_sem_under = SVC(kernel='linear')  # You can try different kernels and hyperparameters\n",
        "\n",
        "# Treinando modelo\n",
        "svm_model_sem_under.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "predictions_sem_under = svm_model_sem_under.predict(X_test)\n",
        "\n",
        "# Avaliando\n",
        "print(classification_report(y_test, predictions_sem_under))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, predictions_sem_under))"
      ],
      "metadata": {
        "id": "Z0D_CSd706Gq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm_sem_under = confusion_matrix(y_test, predictions_sem_under)\n",
        "plot_confusion_matrix(conf_mat = cm_sem_under, show_normed = True, class_names = [0,1,2,3])"
      ],
      "metadata": {
        "id": "ZXpeWCM81Tkc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}